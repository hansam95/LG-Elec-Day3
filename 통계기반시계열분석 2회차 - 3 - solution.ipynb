{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [예측모델 - Solution] \n",
    "\n",
    "## - 구간평균법 \n",
    "## - 단순지수평활법 \n",
    "## - 이중지수평활법 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 모듈 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import pandas_datareader.data as pdr\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true-y_pred)/y_true))*100\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "import seaborn as sns\n",
    "#sns.set_style(\"white\")\n",
    "\n",
    "import itertools\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. 데이터 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google trend에서 2012년부터 2022년까지 10년간 '데이터분석 ' 키워드 관심도 변화량\n",
    "# https://trends.google.com/trends/explore?date=2012-01-01%202022-01-01&geo=KR&q=%EB%8D%B0%EC%9D%B4%ED%84%B0%EB%B6%84%EC%84%9D\n",
    "data = pd.read_csv('./googletrend_keyword.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1 Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change column name\n",
    "data = data.rename(columns={'카테고리: 모든 카테고리': 'data_analysis(korea)'})\n",
    "data = data[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the column type to numeric\n",
    "data = data.astype(np.int64(data['data_analysis(korea)']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the index type to datetime\n",
    "data.index = pd.to_datetime(data.index)\n",
    "data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "데이터 시각화를 통해 전체 개요 확인\n",
    "'''\n",
    "data.plot(figsize=(12,4)) # color='green', linestyle='--', linewidth=1\n",
    "\n",
    "plt.xticks(fontsize=11)\n",
    "plt.yticks(fontsize=11)\n",
    "plt.legend('')\n",
    "\n",
    "plt.title(\"'Data analysis' keyword search amount from Google trend \\n\", fontsize=15)\n",
    "plt.xlabel('\\n Year', fontsize=13)\n",
    "plt.ylabel('keyword search amount \\n', fontsize=13)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seasonal decomposition plot: Seasonal decomposition using moving averages.\n",
    "# https://www.statsmodels.org/stable/generated/statsmodels.tsa.seasonal.seasonal_decompose.html\n",
    "\n",
    "# Observed: observed data\n",
    "# Trend: The estimated trend component\n",
    "# Seasonal: The estimated seasonal component\n",
    "# resid: The estimated residuals\n",
    "\n",
    "decompostion = sm.tsa.seasonal_decompose(data['data_analysis(korea)'],  model='additive')\n",
    "\n",
    "fig = decompostion.plot()\n",
    "fig.set_size_inches(10,10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Train Test Split\n",
    "'''\n",
    "train = data[:'2019-12']\n",
    "test  = data['2020-01':]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Moving Average (구간평균법)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Version 1\n",
    "'''\n",
    "def Moving_Average(x, N):\n",
    "    x = x.values.flatten()\n",
    "    \n",
    "    pred = np.convolve(x, np.ones(N) / float(N), 'valid')\n",
    "    pred = np.concatenate((np.zeros(N-1), pred), axis=0)\n",
    "    pred[:N-1] = np.nan\n",
    "    return pred\n",
    "\n",
    "MA_train_pred = pd.DataFrame(Moving_Average(train, 5), index=train.index, columns=['MA_5'])\n",
    "MA_test_pred = pd.DataFrame(np.array([MA_train_pred.iloc[-1]]*len(test)), index=test.index, columns=['MA_5'])\n",
    "\n",
    "print('Moving Average Train results')\n",
    "print(MA_train_pred)\n",
    "print('-'*30)\n",
    "print('Moving Average Test results')\n",
    "print(MA_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Version 2\n",
    "'''\n",
    "MA_train_pred = train.rolling(5).mean() # Option: min_periods=1\n",
    "MA_train_pred.columns = ['MA_5']\n",
    "\n",
    "MA_test_pred = pd.DataFrame(np.array([MA_train_pred.iloc[-1]]*len(test)), index=test.index, columns=['MA_5'])\n",
    "prediction = pd.concat([MA_train_pred, MA_test_pred], axis=0)\n",
    "\n",
    "print('Moving Average Train Results')\n",
    "print(MA_train_pred)\n",
    "print('-'*30)\n",
    "print('Moving Average Test Results')\n",
    "print(MA_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Visualization \n",
    "'''\n",
    "fig, ax = plt.subplots(figsize=(12,4))\n",
    "data.plot(ax=ax)\n",
    "prediction.plot(ax=ax, label = 'Prediction (N=5)') #ax 로 하나의 plot에 표현\n",
    "ax.vlines(test.index[0], 0, 100, linestyle='--', color='r')\n",
    "ax.legend(['Raw Dataset', 'Prediction (N=5)', 'Start of Forecast'], loc='upper left')\n",
    "plt.title('Moving Average Results (Train and Test)')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Only Test\n",
    "fig, ax = plt.subplots(figsize=(12,4))\n",
    "data.plot(ax=ax)\n",
    "MA_test_pred.plot(ax=ax, label = 'Prediction (N=5)')\n",
    "ax.vlines(test.index[0], 0, 100, linestyle='--', color='r')\n",
    "ax.legend(['Raw Dataset', 'Prediction (N=5)', 'Start of Forecast'], loc='upper left')\n",
    "plt.title('Moving Average Results (Only Test)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 정량적 지표를 통한 모델 검증"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Mean Squared Error (평균 제곱 오차) <br>\n",
    "$\\frac{1}{n} \\sum_{i=1}^{n} (y_{i} - \\hat{y}_{i})^{2}$   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'MSE: {np.round(mean_squared_error(test, MA_test_pred), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "######  Root Mean Squared Error (제곱근 평균 제곱 오차) <br>\n",
    "$\\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (y_{i} - \\hat{y}_{i})^{2}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'RMSE: {np.round(np.sqrt(mean_squared_error(test,MA_test_pred)), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Mean Absolute Error (평균 절대 오차) <br>\n",
    "$\\frac{1}{n} \\sum_{i=1}^{n} |y_{i} - \\hat{y}_{i}|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'MAE: {np.round(mean_absolute_error(test, MA_test_pred), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  R squared (결정계수 $({r})^{2}$) <br>\n",
    "$\\frac{SSR}{SST} = 1- \\frac{SSR}{SST}%$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'R2 score: {np.round(r2_score(test, MA_test_pred), 2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Exponential Smoothing (지수평활법)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1 Simple Exponential Smoothing (단순지수평활법)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L_0 = np.mean(train)  # initial value\n",
    "\n",
    "SES_train = train.copy()\n",
    "SES_train = pd.concat([pd.DataFrame(np.zeros(1), columns=['data_analysis(korea)']), SES_train])\n",
    "SES_train['Level'] = np.nan\n",
    "SES_train['Forecast'] = np.nan\n",
    "SES_train.loc[0,'Level'] = L_0.values\n",
    "\n",
    "SES_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Version 1\n",
    "'''\n",
    "def Simple_Exponential_Smoothing(table, alpha):\n",
    "    # table = SES_train.copy()\n",
    "    # alpha = 0.9\n",
    "    for i in range(len(table)):\n",
    "        if i == 0: # Skip initialization point\n",
    "            continue\n",
    "\n",
    "        x = table.loc[list(table.index)[i],'data_analysis(korea)']\n",
    "        L_prev = table.loc[list(table.index)[i-1],'Level']\n",
    "        table.loc[list(table.index)[i],'Level'] = alpha*x + (1-alpha)*(L_prev)\n",
    "\n",
    "        L_pred = table.iloc[-1,1]\n",
    "        SES_test_pred = [L_pred]*len(test)\n",
    "        SES_test_pred = pd.DataFrame(SES_test_pred, index=test.index, columns=[f'SES_{alpha}'])\n",
    "        \n",
    "    return table, SES_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SES_train_pred, SES_test_pred = Simple_Exponential_Smoothing(SES_train, 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Simple Exponential Smoothing Train Results')\n",
    "print(SES_train_pred)\n",
    "print('-'*30)\n",
    "print('Simple Exponential Smoothing Test results')\n",
    "print(SES_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Version 2\n",
    "'''\n",
    "\n",
    "SES_train_pred_09 = pd.concat([pd.DataFrame([L_0], columns=['data_analysis(korea)']), train]).ewm(alpha=0.9, adjust=False).mean().iloc[1:] #mean?\n",
    "SES_train_pred_09.columns = ['SES_09']\n",
    "SES_test_pred_09 = pd.DataFrame(np.array([SES_train_pred_09.iloc[-1]]*len(test)),\n",
    "                                index=test.index, columns=['SES_09'])\n",
    "prediction_09 = pd.concat([SES_train_pred_09, SES_test_pred_09], axis=0)\n",
    "\n",
    "SES_train_pred_05 = pd.concat([pd.DataFrame([L_0], columns=['data_analysis(korea)']), train]).ewm(alpha=0.5, adjust=False).mean().iloc[1:]\n",
    "SES_train_pred_05.columns = ['SES_05']\n",
    "SES_test_pred_05 = pd.DataFrame(np.array([SES_train_pred_05.iloc[-1]]*len(test)),\n",
    "                                index=test.index, columns=['SES_05'])\n",
    "prediction_05 = pd.concat([SES_train_pred_05, SES_test_pred_05], axis=0)\n",
    "\n",
    "SES_train_pred_01 = pd.concat([pd.DataFrame([L_0], columns=['data_analysis(korea)']), train]).ewm(alpha=0.1, adjust=False).mean().iloc[1:]\n",
    "SES_train_pred_01.columns = ['SES_01']\n",
    "SES_test_pred_01 = pd.DataFrame(np.array([SES_train_pred_01.iloc[-1]]*len(test)),\n",
    "                                index=test.index, columns=['SES_01'])\n",
    "prediction_01 = pd.concat([SES_train_pred_01, SES_test_pred_01], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Visualization \n",
    "'''\n",
    "fig, ax = plt.subplots(figsize=(12,4))\n",
    "data.plot(ax=ax)\n",
    "prediction_09.plot(ax=ax, label = 'Prediction (alpha=0.9)')\n",
    "prediction_05.plot(ax=ax, label = 'Prediction (alpha=0.5)')\n",
    "prediction_01.plot(ax=ax, label = 'Prediction (alpha=0.1)')\n",
    "\n",
    "ax.vlines(test.index[0], 0, 100, linestyle='--', color='r')\n",
    "ax.legend(['Raw Dataset', 'Prediction (alpha=0.9)', 'Prediction (alpha=0.5)', 'Prediction (alpha=0.1)', 'Start of Forecast'], loc='upper left')\n",
    "plt.suptitle('Exponential Moving Average Results')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Only Test\n",
    "fig, ax = plt.subplots(figsize=(12,4))\n",
    "data['2020-01':'2022-01'].plot(ax=ax)\n",
    "prediction_09['2020-01':'2022-01'].plot(ax=ax, label = 'Prediction (alpha=0.9)')\n",
    "prediction_05['2020-01':'2022-01'].plot(ax=ax, label = 'Prediction (alpha=0.5)')\n",
    "prediction_01['2020-01':'2022-01'].plot(ax=ax, label = 'Prediction (alpha=0.1)')\n",
    "\n",
    "ax.vlines(test.index[0], 50, 100, linestyle='--', color='r')\n",
    "ax.legend(['Raw Dataset', 'Prediction (alpha=0.9)', 'Prediction (alpha=0.5)', 'Prediction (alpha=0.1)', 'Start of Forecast'], loc='upper left')\n",
    "plt.suptitle('Exponential Moving Average Results')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Double Exponential Smoothing (이중지수평활법)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Searching Initialization Points\n",
    "'''\n",
    "train_reg = train.reset_index()\n",
    "x = np.array(train_reg.index)\n",
    "y = train_reg['data_analysis(korea)']\n",
    "\n",
    "x = sm.add_constant(x)\n",
    "model = sm.OLS(y,x)\n",
    "results = model.fit()\n",
    "\n",
    "print(results.summary())\n",
    "L_0, B_0 = results.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DES_train = train.copy()\n",
    "DES_train = pd.concat([pd.DataFrame(np.zeros(1), columns=['data_analysis(korea)']), DES_train])\n",
    "DES_train['Level'] = np.nan\n",
    "DES_train['Trend'] = np.nan\n",
    "DES_train['Forecast'] = np.nan\n",
    "\n",
    "DES_train.loc[0,'Level'] = L_0\n",
    "DES_train.loc[0,'Trend'] = B_0\n",
    "\n",
    "DES_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Double_Exponential_Smoothing(table, alpha, beta):\n",
    "    # table = DES_train.copy()\n",
    "    # alpha = 0.16\n",
    "    # beta = 0.1\n",
    "    for i in range(len(table)):\n",
    "        if i == 0: # Skip initialization point\n",
    "            continue\n",
    "\n",
    "        x = table.loc[list(table.index)[i],'data_analysis(korea)']\n",
    "        L_prev = table.loc[list(table.index)[i-1],'Level']\n",
    "        T_prev = table.loc[list(table.index)[i-1],'Trend']\n",
    "        \n",
    "        table.loc[list(table.index)[i],'Level'] = alpha*x + (1-alpha)*(L_prev+T_prev)\n",
    "        table.loc[list(table.index)[i],'Trend'] = beta*(table.loc[list(table.index)[i],'Level']-L_prev) + (1-beta)*(T_prev)\n",
    "\n",
    "        L_Pred = table.iloc[-1,1]\n",
    "        T_Pred = table.iloc[-1,2]\n",
    "        \n",
    "        DES_test_pred = L_Pred + range(len(test))*T_Pred\n",
    "        DES_test_pred = pd.DataFrame(DES_test_pred, index = test.index, columns=['DES'])\n",
    "        \n",
    "    return table, DES_test_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DES_train_pred, DES_test_pred = Double_Exponential_Smoothing(DES_train, 0.16, 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Double Exponential Smoothing Train Results')\n",
    "print(DES_train_pred)\n",
    "print('-'*30)\n",
    "print('Double Exponential Smoothing Test results')\n",
    "print(DES_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Visualization \n",
    "'''\n",
    "# Train and Test\n",
    "train_pred = pd.DataFrame(DES_train_pred.iloc[1:,1])\n",
    "train_pred.columns = ['DES']\n",
    "DES_pred = pd.concat([train_pred, DES_test_pred])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,4))\n",
    "data.plot(ax=ax)\n",
    "DES_pred.plot(ax=ax, label = 'Prediction (alpha=0.16, beta=0.1)')\n",
    "ax.vlines(test.index[0], 0, 100, linestyle='--', color='r')\n",
    "ax.legend(['Raw Dataset', 'DEMA (alpha=0.16, beta=0.1)', 'Start of Forecast'], loc='upper left')\n",
    "plt.suptitle('Double Exponential Moving Average Results')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Comparing\n",
    "'''\n",
    "fig, ax = plt.subplots(figsize=(12,4))\n",
    "data['2020-01':].plot(ax=ax)\n",
    "MA_test_pred['2020-01':].plot(ax=ax, label = 'Prediction (N=5)')\n",
    "SES_test_pred_09['2020-01':].plot(ax=ax, label = 'Prediction (alpha=0.9)')\n",
    "DES_test_pred['2020-01':].plot(ax=ax, label = 'Prediction (alpha=0.16, beta=0.1)')\n",
    "ax.legend(['Raw Dataset', 'MA (N=5)', 'SES (alpha=0.9)', 'DES (alpha=0.16, beta=0.1)'], loc='upper left')\n",
    "plt.suptitle('Double Exponential Moving Average Results')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Holt-Winter's Exponential Smoothing (홀트-윈터 지수평활법)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.3.1 Additive Winter's method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.holtwinters import ExponentialSmoothing\n",
    "HW_model = ExponentialSmoothing(train, trend='add', seasonal='add').fit(optimized=True)\n",
    "HW_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HW_train_pred = HW_model.fittedvalues\n",
    "HW_test_pred = HW_model.forecast(len(test))\n",
    "HW_test_pred = pd.DataFrame(HW_test_pred, index=test.index, columns=['HW_add'])\n",
    "\n",
    "print('Holt-Winter Exponential Smoothing Train Results')\n",
    "print(HW_train_pred)\n",
    "print('-'*30)\n",
    "print('Holt-Winter Smoothing Test results')\n",
    "print(HW_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Visualization \n",
    "'''\n",
    "# Train and Test\n",
    "train_pred = pd.DataFrame(HW_train_pred, columns=['HW_add'])\n",
    "HW_add_pred = pd.concat([train_pred, HW_test_pred])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12,4))\n",
    "data.plot(ax=ax)\n",
    "HW_add_pred.plot(ax=ax, label = 'Prediction')\n",
    "ax.vlines(test.index[0], 0, 100, linestyle='--', color='r')\n",
    "ax.legend(['Raw Dataset', 'HW', 'Start of Forecast'], loc='upper left')\n",
    "plt.title('Holt-Winter Exponential Moving Average Results')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Comparing\n",
    "'''\n",
    "fig, ax = plt.subplots(figsize=(12,4))\n",
    "data.plot(ax=ax)\n",
    "MA_test_pred['2020-01':].plot(ax=ax, label = 'Prediction (N=5)')\n",
    "SES_test_pred_09['2020-01':].plot(ax=ax, label = 'Prediction (alpha=0.9)')\n",
    "DES_test_pred['2020-01':].plot(ax=ax, label = 'Prediction (alpha=0.16, beta=0.1)')\n",
    "HW_test_pred['2020-01':].plot(ax=ax, label = 'Prediction (additive)')\n",
    "ax.vlines(test.index[0], 0, 100, linestyle='--', color='r')\n",
    "ax.legend(['Raw Dataset', 'MA (N=5)', 'SES (alpha=0.9)', 'DES (alpha=0.16, beta=0.1)', 'HW (Additive)'], loc='upper left')\n",
    "plt.title('Double Exponential Moving Average Results')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Quantitative Evaluation\n",
    "'''\n",
    "print('-'*55)\n",
    "print('Moving Average (N = 5)')\n",
    "print(f'MSE: {np.round(mean_squared_error(test, MA_test_pred), 2)}')\n",
    "print(f'RMSE: {np.round(np.sqrt(mean_squared_error(test,MA_test_pred)), 2)}')\n",
    "print(f'MAE: {np.round(mean_absolute_error(test, MA_test_pred), 2)}')\n",
    "\n",
    "print('-'*55)\n",
    "print('Simple Exponential Smoothing (alpha = 0.9)')\n",
    "print(f'MSE: {np.round(mean_squared_error(test, SES_test_pred_09), 2)}')\n",
    "print(f'RMSE: {np.round(np.sqrt(mean_squared_error(test,SES_test_pred_09)), 2)}')\n",
    "print(f'MAE: {np.round(mean_absolute_error(test, SES_test_pred_09), 2)}')\n",
    "\n",
    "print('-'*55)\n",
    "print('Double Exponential Smoothing (alpha = 0.16, beta = 0.1)')\n",
    "print(f'MSE: {np.round(mean_squared_error(test, DES_test_pred), 2)}')\n",
    "print(f'RMSE: {np.round(np.sqrt(mean_squared_error(test,DES_test_pred)), 2)}')\n",
    "print(f'MAE: {np.round(mean_absolute_error(test, DES_test_pred), 2)}')\n",
    "\n",
    "print('-'*55)\n",
    "print('Additive Holt-Winter Exponential Smoothing')\n",
    "print(f'MSE: {np.round(mean_squared_error(test, HW_test_pred), 2)}')\n",
    "print(f'RMSE: {np.round(np.sqrt(mean_squared_error(test,HW_test_pred)), 2)}')\n",
    "print(f'MAE: {np.round(mean_absolute_error(test, HW_test_pred), 2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict_results = pd.concat([test, MA_test_pred, SES_test_pred_09, DES_test_pred, HW_test_pred], axis=1)\n",
    "test_predict_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EOD"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": "1",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "357.469px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
